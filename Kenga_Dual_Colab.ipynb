 {
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Импортируем модули для обучения и инференса\n",
    "from src.neural.models.kenga import KengaConfig, KengaModel\n",
    "from src.neural.training import KengaTrainer\n",
    "from src.neural.data import TextDataset\n",
    "from src.utils.tokenizer import Tokenizer\n",
    "\n",
    "from src.neural.models.kenga_s import KengaSConfig, KengaSModel\n",
    "from src.neural.training_kenga_s import KengaSTrainer\n",
    "\n",
    "def generate_tokens(files, tokenizer):\n",
    "    tokens = []\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    t = tokenizer.encode(line)\n",
    "                    if t:\n",
    "                        tokens.append(t)\n",
    "    return tokens\n",
    "\n",
    "# Создаем директории и файлы с данными\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "train_files = [\"data/train.txt\"]\n",
    "val_files = [\"data/val.txt\"]\n",
    "for file in train_files + val_files:\n",
    "    if not os.path.exists(file):\n",
    "        with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"This is a sample sentence.\\nThis is another sentence.\\n\")\n",
    "\n",
    "# Инициализируем токенизатор, обучаем его и сохраняем\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.train(train_files)\n",
    "tokenizer.save(\"models\", \"kenga\")\n",
    "\n",
    "train_tokens = generate_tokens(train_files, tokenizer)\n",
    "val_tokens = generate_tokens(val_files, tokenizer)\n",
    "\n",
    "train_dataset = TextDataset(train_tokens)\n",
    "val_dataset = TextDataset(val_tokens)\n",
    "\n",
    "# Инициализация модели Kenga (MML) и тренера\n",
    "config = KengaConfig()\n",
    "config.vocab_size = tokenizer.vocab_size\n",
    "model_mml = KengaModel(config)\n",
    "trainer_mml = KengaTrainer(model_mml, train_dataset, val_dataset, {\n",
    "    \"lr\": 1e-4,\n",
    "    \"batch_size\": 4,\n",
    "    \"epochs\": 5,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"model_path\": \"models/kenga.pth\"\n",
    "})\n",
    "\n",
    "# Инициализация модели KengaS (SML) и тренера\n",
    "config_s = KengaSConfig()\n",
    "config_s.vocab_size = tokenizer.vocab_size\n",
    "model_sml = KengaSModel(config_s)\n",
    "trainer_sml = KengaSTrainer(model_sml, train_dataset, val_dataset, {\n",
    "    \"lr\": 1e-4,\n",
    "    \"batch_size\": 4,\n",
    "    \"epochs\": 5,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"model_path\": \"models/kengaS.pth\"\n",
    "})\n",
    "\n",
    "# Запускаем параллельное обучение обеих моделей\n",
    "import threading\n",
    "t1 = threading.Thread(target=trainer_mml.train)\n",
    "t2 = threading.Thread(target=trainer_sml.train)\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "# После обучения выводим тестовый инференс\n",
    "model_mml.eval()\n",
    "model_sml.eval()\n",
    "input_ids = torch.randint(0, tokenizer.vocab_size, (1, 10))\n",
    "mml_output = model_mml(input_ids)\n",
    "sml_output = model_sml(input_ids)\n",
    "print(\"Kenga (MML) Output:\", mml_output)\n",
    "print(\"KengaS (SML) Output:\", sml_output)\n",
    "\n",
    "# Выводим графики прогресса обучения (если тренеры записали историю потерь)\n",
    "if trainer_mml.train_loss_history and trainer_sml.train_loss_history:\n",
    "    epochs_mml = range(1, len(trainer_mml.train_loss_history) + 1)\n",
    "    epochs_sml = range(1, len(trainer_sml.train_loss_history) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs_mml, trainer_mml.train_loss_history, label='Train Loss (MML)')\n",
    "    plt.plot(epochs_mml, trainer_mml.val_loss_history, label='Val Loss (MML)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Kenga (MML) Training Progress')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs_sml, trainer_sml.train_loss_history, label='Train Loss (SML)')\n",
    "    plt.plot(epochs_sml, trainer_sml.val_loss_history, label='Val Loss (SML)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('KengaS (SML) Training Progress')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "push-to-gitlab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если настроены креденциалы Git, можно отправить чекпоинты в GitLab\n",
    "!git config --global user.email \"your_email@example.com\"\n",
    "!git config --global user.name \"Your Name\"\n",
    "!git add models/\n",
    "!git commit -m \"Обновленные чекпоинты и графики обучения после тренировки в Colab\"\n",
    "!git push gitlab main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
